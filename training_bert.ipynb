{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a27a4194",
   "metadata": {},
   "source": [
    "Importing and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60633e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForMaskedLM\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e70f3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training_text data\n",
    "df = pd.read_csv('/Users/Niek/pollob/data/training_text.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99248a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loops over the text in the text column and applies BeautifulSoup to split text based on the html tags\n",
    "text_fragments = []\n",
    "for text in df['text']:\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    for sentence in soup.get_text().split('.'):\n",
    "        if sentence.strip():\n",
    "            text_fragments.append({'text': sentence.strip()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33820c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned df with text that was split with html tag in a new row\n",
    "cleaned_df = pd.DataFrame(text_fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8831ac3",
   "metadata": {},
   "source": [
    "Importing the BERT Transformers from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f535c03",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# NLPTown\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tokenizernlptown \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnlptown/bert-base-multilingual-uncased-sentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m modelnlptown \u001b[38;5;241m=\u001b[39m AutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnlptown/bert-base-multilingual-uncased-sentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentiment_score\u001b[39m(text):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# NLPTown\n",
    "tokenizernlptown = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "modelnlptown = AutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "def sentiment_score(text):\n",
    "    tokens = tokenizer.encode(text, return_tensors='pt')\n",
    "    result = model(tokens)\n",
    "    return int(torch.argmax(result.logits))+1\n",
    "\n",
    "annotated['label'].value_counts()\n",
    "#use tqdm to track progress of the apply function\n",
    "tqdm.pandas()  \n",
    "annotated['sentiment_score_multi'] = annotated['text'].progress_apply(lambda x: sentiment_score(x))\n",
    "# 32 seconds\n",
    "\n",
    "def analysis_multi(score):\n",
    "    if score < 3:\n",
    "        return -1\n",
    "    elif score == 3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "      \n",
    "annotated['sentiment_multi'] = annotated['sentiment_score_multi'].progress_apply(lambda x: analysis_multi(x))\n",
    "print(metrics.classification_report(annotated['label'],annotated['sentiment_multi'], digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ab53ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DTAI\n",
    "tokenizerDTAI = AutoTokenizer.from_pretrained(\"DTAI-KULeuven/robbert-v2-dutch-sentiment\")\n",
    "modelDTAI = AutoModelForSequenceClassification.from_pretrained(\"DTAI-KULeuven/robbert-v2-dutch-sentiment\")\n",
    "\n",
    "def softmax(z): return np.exp(z)/((np.exp(z)).sum())\n",
    "\n",
    "def sentiment_score_DTAI(text):\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    scores_dict = {\n",
    "    -1 : scores[0],\n",
    "    0 : scores[1],\n",
    "    1 : scores[2]\n",
    "  }\n",
    "    max_value = max(scores_dict, key=scores_dict.get)\n",
    "    return max_value\n",
    "  \n",
    "annotated['sentiment_score_DTAI'] = annotated['text'].progress_apply(lambda x: sentiment_score_DTAI(x))\n",
    "print(metrics.classification_report(annotated['label'],annotated['sentiment_score_DTAI'], digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ec873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gilesitorr finetuned\n",
    "tokenizergil = AutoTokenizer.from_pretrained(\"gilesitorr/bert-base-multilingual-uncased-sentiment-3labels\")\n",
    "modelgil = AutoModelForSequenceClassification.from_pretrained(\"gilesitorr/bert-base-multilingual-uncased-sentiment-3labels\")\n",
    "\n",
    "def sentiment_score_gil(text):\n",
    "    tokens = tokenizergil.encode(text, return_tensors='pt')\n",
    "    result = modelgil(tokens)\n",
    "    return int(torch.argmax(result.logits))+1\n",
    "  \n",
    "annotated['sentiment_score_gil'] = annotated['text'].progress_apply(lambda x: sentiment_score_gil(x))\n",
    "# -> took 30 seconds\n",
    "\n",
    "def analysis_gil(score):\n",
    "    if score == 3:\n",
    "        return 1\n",
    "    if score == 2:\n",
    "        return 0\n",
    "    elif score == 1:\n",
    "        return -1\n",
    "    \n",
    "annotated['sentiment_gil'] = annotated['sentiment_score_gil'].progress_apply(lambda x: analysis_gil(x))\n",
    "print(metrics.classification_report(annotated['label'],annotated['sentiment_gil'], digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaacbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the agreement of the three models on the sample\n",
    "annotated['sentiment_multi'] = annotated['sentiment_score_multi'].progress_apply(lambda x: analysis_multi(x))\n",
    "annotated['sentiment_score_DTAI'] = annotated['text'].progress_apply(lambda x: sentiment_score_DTAI(x))\n",
    "annotated['sentiment_gil'] = annotated['sentiment_score_gil'].progress_apply(lambda x: analysis_gil(x))\n",
    "\n",
    "annotated['agreement_models'] = np.where((((annotated['sentiment_multi'])==(annotated['sentiment_score_DTAI']))& (annotated['sentiment_score_DTAI'] == annotated['sentiment_gil'])),annotated['sentiment_multi'],None)\n",
    "annotated['agreement_models'].sum() / len(annotated['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

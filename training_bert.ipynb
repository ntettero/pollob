{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6fbbe46",
   "metadata": {},
   "source": [
    "Importing and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9145feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForMaskedLM\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7e101fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use tqdm to track progress of the apply function\n",
    "tqdm.pandas()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a0c67b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training_text data\n",
    "df = pd.read_csv('/Users/Niek/pollob/data/training_text.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bee3687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loops over the text in the text column and applies BeautifulSoup to split text based on the html tags\n",
    "text_fragments = []\n",
    "for text in df['text']:\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    for sentence in soup.get_text().split('.'):\n",
    "        if sentence.strip():\n",
    "            text_fragments.append({'text': sentence.strip()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f14f8980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned df with text that was split with html tag in a new row\n",
    "cleaned_df = pd.DataFrame(text_fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db20cd71",
   "metadata": {},
   "source": [
    "Importing the BERT Transformers from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7313772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                    | 830/442909 [01:07<8:56:30, 13.73it/s]"
     ]
    }
   ],
   "source": [
    "# NLPTown\n",
    "tokenizernlptown = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "modelnlptown = AutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "def sentiment_score(text):\n",
    "    tokens = tokenizernlptown.encode(text, return_tensors='pt')\n",
    "    result = modelnlptown(tokens)\n",
    "    return int(torch.argmax(result.logits))+1\n",
    "\n",
    "cleaned_df['sentiment_score_multi'] = cleaned_df['text'].progress_apply(lambda x: sentiment_score(x))\n",
    "# 32 seconds\n",
    "\n",
    "def analysis_multi(score):\n",
    "    if score < 3:\n",
    "        return -1\n",
    "    elif score == 3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "      \n",
    "cleaned_df['sentiment_multi'] = cleaned_df['sentiment_score_multi'].progress_apply(lambda x: analysis_multi(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adddd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DTAI\n",
    "tokenizerDTAI = AutoTokenizer.from_pretrained(\"DTAI-KULeuven/robbert-v2-dutch-sentiment\")\n",
    "modelDTAI = AutoModelForSequenceClassification.from_pretrained(\"DTAI-KULeuven/robbert-v2-dutch-sentiment\")\n",
    "\n",
    "def softmax(z): return np.exp(z)/((np.exp(z)).sum())\n",
    "\n",
    "def sentiment_score_DTAI(text):\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    scores_dict = {\n",
    "    -1 : scores[0],\n",
    "    0 : scores[1],\n",
    "    1 : scores[2]\n",
    "  }\n",
    "    max_value = max(scores_dict, key=scores_dict.get)\n",
    "    return max_value\n",
    "  \n",
    "cleaned_df['sentiment_score_DTAI'] = cleaned_df['text'].progress_apply(lambda x: sentiment_score_DTAI(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad951b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gilesitorr finetuned\n",
    "tokenizergil = AutoTokenizer.from_pretrained(\"gilesitorr/bert-base-multilingual-uncased-sentiment-3labels\")\n",
    "modelgil = AutoModelForSequenceClassification.from_pretrained(\"gilesitorr/bert-base-multilingual-uncased-sentiment-3labels\")\n",
    "\n",
    "def sentiment_score_gil(text):\n",
    "    tokens = tokenizergil.encode(text, return_tensors='pt')\n",
    "    result = modelgil(tokens)\n",
    "    return int(torch.argmax(result.logits))+1\n",
    "  \n",
    "cleaned_df['sentiment_score_gil'] = cleaned_df['text'].progress_apply(lambda x: sentiment_score_gil(x))\n",
    "# -> took 30 seconds\n",
    "\n",
    "def analysis_gil(score):\n",
    "    if score == 3:\n",
    "        return 1\n",
    "    if score == 2:\n",
    "        return 0\n",
    "    elif score == 1:\n",
    "        return -1\n",
    "    \n",
    "cleaned_df['sentiment_gil'] = cleaned_df['sentiment_score_gil'].progress_apply(lambda x: analysis_gil(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a86c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the agreement of the three models on the sample\n",
    "annotated['sentiment_multi'] = annotated['sentiment_score_multi'].progress_apply(lambda x: analysis_multi(x))\n",
    "annotated['sentiment_score_DTAI'] = annotated['text'].progress_apply(lambda x: sentiment_score_DTAI(x))\n",
    "annotated['sentiment_gil'] = annotated['sentiment_score_gil'].progress_apply(lambda x: analysis_gil(x))\n",
    "\n",
    "annotated['agreement_models'] = np.where((((annotated['sentiment_multi'])==(annotated['sentiment_score_DTAI']))& (annotated['sentiment_score_DTAI'] == annotated['sentiment_gil'])),annotated['sentiment_multi'],None)\n",
    "annotated['agreement_models'].sum() / len(annotated['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
